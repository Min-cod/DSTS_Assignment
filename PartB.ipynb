{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eb0fe59",
   "metadata": {},
   "source": [
    "## Part B  Predictive Modelling\n",
    "\n",
    "https://medium.com/analytics-vidhya/implementing-linear-regression-using-sklearn-76264a3c073c\n",
    "\n",
    "https://www.kaggle.com/srivignesh/data-preprocessing-for-house-price-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cabf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "OUTPUT_DIR = 'data/'\n",
    "\n",
    "# Load data\n",
    "file_name = 'zomato_df_final_data.csv'\n",
    "df = pd.read_csv(DATA_DIR + file_name) \n",
    "\n",
    "# Subselect the main cols for analyze\n",
    "df_1 = df[['cost', 'cuisine', 'rating_number', 'subzone', 'type', 'votes', 'groupon','rating_text']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1ca02",
   "metadata": {},
   "source": [
    "### 1. Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0cf0b3",
   "metadata": {},
   "source": [
    "Relationship with numerical variables\n",
    "\n",
    "Relationship with categorical features\n",
    "\n",
    "Correlation matrix (heatmap style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2908e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ColumnName</th>\n",
       "      <th>TotalMissingVals</th>\n",
       "      <th>PercentMissing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cost</td>\n",
       "      <td>346.0</td>\n",
       "      <td>3.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rating_number</td>\n",
       "      <td>3316.0</td>\n",
       "      <td>31.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>votes</td>\n",
       "      <td>3316.0</td>\n",
       "      <td>31.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rating_text</td>\n",
       "      <td>3316.0</td>\n",
       "      <td>31.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ColumnName  TotalMissingVals  PercentMissing\n",
       "0           cost             346.0            3.30\n",
       "2  rating_number            3316.0           31.58\n",
       "4           type              48.0            0.46\n",
       "5          votes            3316.0           31.58\n",
       "7    rating_text            3316.0           31.58"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of columns with missing values:5\n"
     ]
    }
   ],
   "source": [
    "#clean data\n",
    "\n",
    "#find missing data\n",
    "def find_missing_percent(data):\n",
    "    \"\"\"\n",
    "    Returns dataframe containing the total missing values and percentage of total\n",
    "    missing values of a column.\n",
    "    \"\"\"\n",
    "    miss_df = pd.DataFrame({'ColumnName':[],'TotalMissingVals':[],'PercentMissing':[]})\n",
    "    for col in data.columns:\n",
    "        sum_miss_val = data[col].isnull().sum()\n",
    "        percent_miss_val = round((sum_miss_val/data.shape[0])*100,2)\n",
    "        miss_df = miss_df.append(dict(zip(miss_df.columns,[col,sum_miss_val,percent_miss_val])),ignore_index=True)\n",
    "    return miss_df\n",
    "\n",
    "miss_df = find_missing_percent(df_1)\n",
    "\n",
    "# Displays columns with missing values\n",
    "display(miss_df[miss_df['PercentMissing']>0.0])\n",
    "print(\"\\n\")\n",
    "print(f\"Number of columns with missing values:{str(miss_df[miss_df['PercentMissing']>0.0].shape[0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0512710c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7061.000000</td>\n",
       "      <td>7061.000000</td>\n",
       "      <td>7061.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>55.340037</td>\n",
       "      <td>3.287311</td>\n",
       "      <td>84.540575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.247408</td>\n",
       "      <td>0.454621</td>\n",
       "      <td>176.324404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>3236.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              cost  rating_number        votes\n",
       "count  7061.000000    7061.000000  7061.000000\n",
       "mean     55.340037       3.287311    84.540575\n",
       "std      29.247408       0.454621   176.324404\n",
       "min      10.000000       1.800000     4.000000\n",
       "25%      35.000000       3.000000    12.000000\n",
       "50%      50.000000       3.300000    33.000000\n",
       "75%      70.000000       3.600000    88.000000\n",
       "max     500.000000       4.900000  3236.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove NA\n",
    "df_2 = df_1.dropna() \n",
    "df_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "04bcc63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** missing values **********\n",
      "0\n",
      "********** Labels **********\n",
      "[False  True]\n",
      "********** frequency **********\n",
      "False    6960\n",
      "True      101\n",
      "Name: groupon, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# a function to explore each of the categorical variables\n",
    "def explore_categorical(df, var):\n",
    "    # check if the variable has any missing values\n",
    "    print('********** missing values **********')\n",
    "    print(df[var].isnull().sum())\n",
    "    print('********** Labels **********')\n",
    "    # check unique lables in variable\n",
    "    print(df[var].unique())\n",
    "    print('********** frequency **********')\n",
    "    # check frequency of each variable\n",
    "    print(df[var].value_counts())\n",
    "    \n",
    "explore_categorical(df_2, 'groupon')\n",
    "# explore_categorical(data_ready, 'cuisine')\n",
    "# explore_categorical(data_ready, 'subzone')\n",
    "# explore_categorical(data_ready, 'type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad57478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding using dummy\n",
    "\n",
    "# Adding dummy categories into the dataframe\n",
    "df_3 = pd.concat([df_2, pd.get_dummies(df_2['groupon']).astype(int)], axis = 1)\n",
    "\n",
    "# Drop original string based column to avoid conflict in linear regression\n",
    "df_3.drop('groupon', axis = 1, inplace=True)\n",
    "\n",
    "#change the meaningful name for groupon\n",
    "data_ready = df_3.rename(columns= {False: 'no_groupon', True: 'groupon'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60009223",
   "metadata": {},
   "source": [
    "### 2.1 Regression: Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "22cf8ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns : Index(['cost', 'rating_number', 'votes', 'no_groupon', 'groupon'], dtype='object')\n",
      "Categoric columns : Index(['cuisine', 'subzone', 'type'], dtype='object')\n",
      "Boolean columns : Index([], dtype='object')\n",
      "      cost  votes  no_groupon  groupon\n",
      "3715  20.0   16.0           1        0\n",
      "6180  90.0   15.0           1        0\n",
      "347   62.0  201.0           1        0\n"
     ]
    }
   ],
   "source": [
    "# Segregate the numeric and categoric data\n",
    "numeric_cols = data_ready.select_dtypes(['float','int']).columns\n",
    "data_numeric = data_ready[numeric_cols]\n",
    "\n",
    "\n",
    "# get training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_numeric = data_numeric.drop(columns=['rating_number'])\n",
    "y = data_ready[['rating_number']]\n",
    "\n",
    "X_train_numeric, X_test_numeric, y_train, y_test = train_test_split(X_numeric, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "18b80f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1393057078618882"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_regression_1 = LinearRegression().fit(X_train_numeric, y_train)\n",
    "\n",
    "#obtain the MSE of model_1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model_regression_1.predict(X_test_numeric)\n",
    "\n",
    "MSE_linear_1 = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "MSE_linear_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df068b6b",
   "metadata": {},
   "source": [
    "Smaller MSE  is better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2184f25a",
   "metadata": {},
   "source": [
    "### 2.2 Regression: Linear Regression with the gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "31da19ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta = [[ 3.45609065e-01 -8.44612584e-19  1.54278527e-18  8.96604409e-19\n",
      "  -8.96604409e-19]]\n",
      "cost = [938.97298985 906.01043496 876.66618003 850.54304426 827.28744534\n",
      " 806.58461374 788.15433217 771.74714278 757.14097073 744.13811832\n",
      " 732.56258915 722.25770592 713.08398983 704.91727264 697.64701607\n",
      " 691.17481564 685.41306871 680.2837888  675.71754999 671.65254726\n",
      " 668.03375992 664.8122069  661.94428379 659.39117262 657.11831649\n",
      " 655.0949518  653.29369187 651.69015626 650.26264077 648.99182367\n",
      " 647.86050418 646.85336963 645.95678826 645.15862463 644.44807543\n",
      " 643.81552322 643.25240628 642.75110268 642.30482719 641.90753936\n",
      " 641.55386182 641.23900747 640.95871468 640.70918964 640.48705496\n",
      " 640.28930401 640.11326018 639.95654068 639.81702429 639.69282261\n",
      " 639.58225455 639.48382355 639.39619732 639.31818982 639.2487452\n",
      " 639.18692352 639.13188801 639.08289375 639.03927759 639.00044917\n",
      " 638.96588295 638.93511106 638.90771701 638.88333    638.86161995\n",
      " 638.84229301 638.8250876  638.80977082 638.79613536 638.78399667\n",
      " 638.77319044 638.76357041 638.75500638 638.74738241 638.74059533\n",
      " 638.73455327 638.72917445 638.72438605 638.72012328 638.71632844\n",
      " 638.71295015 638.7099427  638.70726538 638.70488195 638.70276014\n",
      " 638.70087125 638.6991897  638.69769273 638.69636009 638.69517373\n",
      " 638.6941176  638.6931774  638.6923404  638.69159528 638.69093196\n",
      " 638.69034144 638.68981575 638.68934776 638.68893115 638.68856026\n",
      " 638.68823009 638.68793616 638.6876745  638.68744156 638.68723418\n",
      " 638.68704958 638.68688523 638.68673893 638.68660868 638.68649274\n",
      " 638.68638952 638.68629763 638.68621582 638.686143   638.68607817\n",
      " 638.68602046 638.68596908 638.68592334 638.68588262 638.68584638\n",
      " 638.68581411 638.68578538 638.68575981 638.68573704 638.68571677\n",
      " 638.68569873 638.68568267 638.68566837 638.68565564 638.68564431\n",
      " 638.68563422 638.68562524 638.68561725 638.68561013 638.68560379\n",
      " 638.68559815 638.68559313 638.68558866 638.68558468 638.68558114\n",
      " 638.68557798 638.68557518 638.68557268 638.68557045 638.68556847\n",
      " 638.68556671 638.68556514 638.68556374 638.6855625  638.68556139\n",
      " 638.6855604  638.68555953 638.68555874 638.68555805 638.68555743\n",
      " 638.68555688 638.68555639 638.68555595 638.68555556 638.68555522\n",
      " 638.68555491 638.68555463 638.68555439 638.68555417 638.68555398\n",
      " 638.68555381 638.68555365 638.68555352 638.68555339 638.68555329\n",
      " 638.68555319 638.6855531  638.68555303 638.68555296 638.6855529\n",
      " 638.68555284 638.6855528  638.68555275 638.68555272 638.68555268\n",
      " 638.68555265 638.68555263 638.6855526  638.68555258 638.68555256\n",
      " 638.68555254 638.68555253 638.68555252 638.6855525  638.68555249\n",
      " 638.68555248 638.68555248 638.68555247 638.68555246 638.68555246\n",
      " 638.68555245 638.68555245 638.68555244 638.68555244 638.68555243\n",
      " 638.68555243 638.68555243 638.68555243 638.68555242 638.68555242\n",
      " 638.68555242 638.68555242 638.68555242 638.68555242 638.68555242\n",
      " 638.68555242 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241\n",
      " 638.68555241 638.68555241 638.68555241 638.68555241 638.68555241]\n"
     ]
    }
   ],
   "source": [
    "# Building linear model with the gradient descent algorithm\n",
    "#  calculates and outputs the hypothesis value of the Target Variable\n",
    "def hypothesis(theta, X, n):\n",
    "    h = np.ones((X.shape[0],1))\n",
    "    theta = theta.reshape(1,n+1)\n",
    "#     print('X.shape[0] = ',X.shape[0])\n",
    "#     print('theta = ',theta)\n",
    "    for i in range(0,X.shape[0]):\n",
    "        h[i] = float(np.matmul(theta, X[i]))\n",
    "#         print('h',i, h[i])\n",
    "    h = h.reshape(X.shape[0])\n",
    "    \n",
    "    return h\n",
    "\n",
    "# performs the Batch Gradient Descent Algorithm\n",
    "def BGD(theta, alpha, num_iters, h, X, y, n):\n",
    "    cost = np.ones(num_iters)\n",
    "    for i in range(0,num_iters):\n",
    "        theta[0] = theta[0] - (alpha/X.shape[0]) * np.sum(h - y)\n",
    "        for j in range(1,n+1):\n",
    "            theta[j] = theta[j] - (alpha/X.shape[0]) * np.sum((h-y) * X.transpose()[j])\n",
    "#             print('np.sum e = ', (alpha/X.shape[0]) * np.sum((h-y) * X.transpose()[j]))\n",
    "#             print('e = ', (alpha/X.shape[0]) * sum((h-y) * X.transpose()[j]))\n",
    "            \n",
    "        h = hypothesis(theta, X, n)\n",
    "        cost[i] = (1/X.shape[0]) * 0.5 * np.sum(np.square(h - y))\n",
    " \n",
    "    theta = theta.reshape(1,n+1)\n",
    "    return theta, cost\n",
    "\n",
    "# outputs the final optimized theta\n",
    "def linear_regression_BGD(X, y, alpha, num_iters):\n",
    "    n = X.shape[1]\n",
    "    one_column = np.ones((X.shape[0],1))\n",
    "    X = np.concatenate((one_column, X), axis = 1)\n",
    "    # initializing the parameter vector...\n",
    "    theta = np.zeros(n+1)\n",
    "    # hypothesis calculation....\n",
    "    h = hypothesis(theta, X, n)\n",
    "    # returning the optimized parameters by Gradient Descent...\n",
    "    theta, cost = BGD(theta,alpha,num_iters,h,X,y,n)\n",
    "    return theta, cost\n",
    "\n",
    "#convert to numpy for processing\n",
    "X_train_numeric_np = X_train_numeric.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "\n",
    "# Implementation of feature scaling\n",
    "mean = np.ones(X_train_numeric_np.shape[1])\n",
    "std = np.ones(X_train_numeric_np.shape[1])\n",
    "\n",
    "for i in range(0, X_train_numeric_np.shape[1]):\n",
    "    mean[i] = np.mean(X_train_numeric_np.transpose()[i])\n",
    "    std[i] = np.std(X_train_numeric_np.transpose()[i])\n",
    "    for j in range(0, X_train_numeric_np.shape[0]):\n",
    "        X_train_numeric_np[j][i] = (X_train_numeric_np[j][i] - mean[i])/std[i]  \n",
    "        \n",
    "# calling the principal function with learning_rate = 0.01 and num_iters = 100\n",
    "theta, cost = linear_regression_BGD(X_train_numeric_np, y_train_np, 0.00001, 500)\n",
    "print('theta =', theta)\n",
    "print('cost =', cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "25a32972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34560907 0.34560907 0.34560907 ... 0.34560907 0.34560907 0.34560907]\n",
      "0.2291473234292452\n"
     ]
    }
   ],
   "source": [
    "# Getting the predictions\n",
    "# X_test = np.concatenate((np.ones((X_test_numeric.shape[0],1)), X_test_numeric),axis = 1)\n",
    "predictions = hypothesis(theta, X_test, X_test.shape[1] - 1)\n",
    "\n",
    "#obtain the MSE of model_2\n",
    "MSE_linear_2 = mean_squared_error(y_test, predictions)\n",
    "print(MSE_linear_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b099cd4c",
   "metadata": {},
   "source": [
    "### 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2309f212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data processing\n",
    "mapping = {'Good': 1, 'Very Good': 1, 'Excellent': 1,'Poor': 0,'Average':0}\n",
    "df_4 = df_3.replace({'rating_text': mapping})\n",
    "numeric_cols = df_4.select_dtypes(['float','int']).columns\n",
    "df_4 = df_4[numeric_cols]\n",
    "\n",
    "X = df_4.drop(columns=['rating_text'])\n",
    "y = df_4[['rating_text']]\n",
    "\n",
    "# get training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0) # this means training size if 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea1aec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.9985845718329794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Making predictions using scikit learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create an instance and fit the model \n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(f\"Accuracy = {lr_model.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483bda9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix : \n",
      " [[502   0]\n",
      " [  2 909]]\n",
      "Classification report : \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       502\n",
      "           0       1.00      1.00      1.00       911\n",
      "\n",
      "    accuracy                           1.00      1413\n",
      "   macro avg       1.00      1.00      1.00      1413\n",
      "weighted avg       1.00      1.00      1.00      1413\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix in sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# confusion matrix (heatmap style)\n",
    "matrix = confusion_matrix(y_test,y_pred, labels=[1,0])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot = True)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix = classification_report(y_test,y_pred,labels=[1,0])\n",
    "print('Classification report : \\n',matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0a9891",
   "metadata": {},
   "source": [
    "### 3.2 Conclusion and observation\n",
    "The rows of the matrix represent the real classes, while the columns represent the predicted classes.\n",
    "\n",
    "Total predictions: 1413\n",
    "\n",
    "Correct predictions: 1411 (502 benign (TN) and 909 malignant (TP))\n",
    "\n",
    "Incorrect predictions: 2 (2 benign classified as malignant (FP) and no malignant classified as benign (FN))\n",
    "\n",
    "The accuracy is 99.85% which means it is a good model, although we should consider the strong correlation between rating_number and rating_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cdc48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
